{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "gOHKC3DMVyEQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9RCrDj8T7R6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Deep Learning workflows\n",
        "\n",
        "1. Data\n",
        "2. Create a Model\n",
        "3. Optimize Model paramter (finding the best weights)\n",
        "4. Save the trained model\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries"
      ],
      "metadata": {
        "id": "v9sRaP6TWR0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch #pytorch library that helps in building the deep leanring algorithms\n",
        "from torch import nn ##nn means neural network\n",
        "from torch.utils.data import DataLoader #performs the process of batching\n",
        "from torchvision import datasets #Inbuild dataset that pytorch library has - FashionMnist Dataset\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "JkXfRNqUWVIe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the data"
      ],
      "metadata": {
        "id": "J4LJeC8LXHay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(root=\"data\",train=True,download=True,transform=ToTensor())\n",
        "test_data = datasets.FashionMNIST(root=\"data\",train=False,download=True,transform=ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7DVR60aW6Ke",
        "outputId": "d3468d07-6447-48e0-e8da-8a435a4ac710"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 12474223.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 212612.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3895773.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5706204.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtK9ODQhXqpO",
        "outputId": "621fb9c0-fa56-48e7-97cb-0e926520a9c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B4imIyWXv-M",
        "outputId": "d7396136-b089-46c2-fceb-1d8081256df2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batching of this data"
      ],
      "metadata": {
        "id": "wAg2gL44XiRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data,batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Ehr4Mih2XZNF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X,y in test_dataloader: #Image - Color image shape (batch_size,number of channel,length,width)\n",
        "  print(X.shape)            #Image - Black and white image - number of channels is 1\n",
        "  print(y.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCr9O9kiYej2",
        "outputId": "f3980dee-c068-4314-a028-963b3690032a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the model"
      ],
      "metadata": {
        "id": "Oyn6eLC5Zyfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #torch.cuda.is_available() checks for your system has gpu or cpu\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_P_or9QtYon-",
        "outputId": "8e539b0f-44b9-4575-a7aa-06be5ae7d692"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module): #Child class and nn.Module is a parent class -- (defined in the pytorch library)\n",
        "\n",
        "  def __init__(self): #declare the architecture\n",
        "    super().__init__() #basically initailizes all the variables of the parent class\n",
        "    self.flatten = nn.Flatten() #28x28 image into a 764x1 vector\n",
        "    self.linear1 = nn.Linear(28*28,512)\n",
        "    self.linear2 = nn.Linear(512,512)\n",
        "    self.linear3 = nn.Linear(512,10)\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):#is always used to pass the inputs to the neural network\n",
        "    x = self.flatten(x)\n",
        "    x = self.linear1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.linear3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "cDqjZ1CNaJWY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model = model.to(device) #copies your entire architecture to the GPU"
      ],
      "metadata": {
        "id": "GPfs4WF1b-KD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization - Gradient Descent + backpropogation"
      ],
      "metadata": {
        "id": "y2_Q36uKcJuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss() #cross entropy loss\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3) #stochastic Gradient descent"
      ],
      "metadata": {
        "id": "LhFE9FmucIVq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#steps in the GD : Batch of the input / Pass it to the model / Compute loss function / Update the weights\n",
        "\n",
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "  model.train() #putting the model in the training mode\n",
        "  for batch,(X,y) in enumerate(dataloader):\n",
        "    #sending the data to the GPU\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    #Compute predictions\n",
        "    pred = model(X)\n",
        "\n",
        "    #Compute loss\n",
        "    loss = loss_fn(pred,y)\n",
        "\n",
        "    #Backpropogation\n",
        "    loss.backward() #Wnew = Wold - lr*dl/dw\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print(f'Loss of the Model {loss.item()}')"
      ],
      "metadata": {
        "id": "5tL18bFBceOR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader,model,loss_fn):\n",
        "  model.eval() #putting the model in the training mode\n",
        "  num_batched = len(dataloader)\n",
        "  test_loss, correct = 0,0\n",
        "  with torch.no_grad(): #We will not compute gradients for the test data\n",
        "    for X,y in dataloader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      #Compute predictions\n",
        "      pred = model(X)\n",
        "\n",
        "      #Compute loss\n",
        "      test_loss += loss_fn(pred,y).item()\n",
        "\n",
        "      #Find how many correct predictions\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss = test_loss/num_batched\n",
        "  correct = correct/(len(dataloader.dataset))\n",
        "\n",
        "  print(f'Test Accuracy {100*correct}, Avg_loss : {test_loss}')"
      ],
      "metadata": {
        "id": "tKqj3ILkd6Dc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Phase"
      ],
      "metadata": {
        "id": "Q77do21CfIDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "for t in range(5):\n",
        "  print(f'Epoch {t+1}')\n",
        "  train(train_dataloader,model,loss_fn,optimizer)\n",
        "  test(test_dataloader,model,loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnEimh6HfDxy",
        "outputId": "60c19687-ce42-421d-b093-4d32371c1d5f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Loss of the Model 1.4052774906158447\n",
            "Loss of the Model 1.3908345699310303\n",
            "Loss of the Model 1.2259663343429565\n",
            "Loss of the Model 1.3262871503829956\n",
            "Loss of the Model 1.2031605243682861\n",
            "Loss of the Model 1.2123459577560425\n",
            "Loss of the Model 1.2250869274139404\n",
            "Loss of the Model 1.1572368144989014\n",
            "Loss of the Model 1.2026647329330444\n",
            "Loss of the Model 1.1122525930404663\n",
            "Test Accuracy 63.89, Avg_loss : 1.1402978570597946\n",
            "Epoch 2\n",
            "Loss of the Model 1.2081586122512817\n",
            "Loss of the Model 1.2136220932006836\n",
            "Loss of the Model 1.0320074558258057\n",
            "Loss of the Model 1.1627304553985596\n",
            "Loss of the Model 1.0343506336212158\n",
            "Loss of the Model 1.0588557720184326\n",
            "Loss of the Model 1.0868233442306519\n",
            "Loss of the Model 1.0234606266021729\n",
            "Loss of the Model 1.0730667114257812\n",
            "Loss of the Model 0.9979758858680725\n",
            "Test Accuracy 65.35, Avg_loss : 1.0176877838790797\n",
            "Epoch 3\n",
            "Loss of the Model 1.0765368938446045\n",
            "Loss of the Model 1.103747010231018\n",
            "Loss of the Model 0.902263343334198\n",
            "Loss of the Model 1.0579943656921387\n",
            "Loss of the Model 0.9312971234321594\n",
            "Loss of the Model 0.9528731107711792\n",
            "Loss of the Model 1.0003840923309326\n",
            "Loss of the Model 0.9370812177658081\n",
            "Loss of the Model 0.9852545857429504\n",
            "Loss of the Model 0.9237912893295288\n",
            "Test Accuracy 66.79, Avg_loss : 0.9358134877150226\n",
            "Epoch 4\n",
            "Loss of the Model 0.9812966585159302\n",
            "Loss of the Model 1.0296704769134521\n",
            "Loss of the Model 0.8098887801170349\n",
            "Loss of the Model 0.9855954051017761\n",
            "Loss of the Model 0.863731324672699\n",
            "Loss of the Model 0.8758246898651123\n",
            "Loss of the Model 0.9412614703178406\n",
            "Loss of the Model 0.8790837526321411\n",
            "Loss of the Model 0.9222254157066345\n",
            "Loss of the Model 0.8706988096237183\n",
            "Test Accuracy 68.06, Avg_loss : 0.877323113808966\n",
            "Epoch 5\n",
            "Loss of the Model 0.9083507657051086\n",
            "Loss of the Model 0.9751027822494507\n",
            "Loss of the Model 0.7405993938446045\n",
            "Loss of the Model 0.931896448135376\n",
            "Loss of the Model 0.8159480690956116\n",
            "Loss of the Model 0.8178430795669556\n",
            "Loss of the Model 0.8967684507369995\n",
            "Loss of the Model 0.8382318615913391\n",
            "Loss of the Model 0.8750935792922974\n",
            "Loss of the Model 0.8300626873970032\n",
            "Test Accuracy 69.53, Avg_loss : 0.8332217639418924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Model"
      ],
      "metadata": {
        "id": "9likkexxhCLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"/content/Weights/iteration1.pth\")"
      ],
      "metadata": {
        "id": "FEERpj8XfdMV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the saveed weights"
      ],
      "metadata": {
        "id": "98EXRWR5hZ7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/Weights/iteration1.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akbyRao8hV7p",
        "outputId": "b67c2205-2ac9-4824-b3f0-0c5881a4e4ab"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ],
      "metadata": {
        "id": "NUigzr90hsRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"]\n",
        "\n",
        "model.eval()\n",
        "X,y = test_data[0][0], test_data[0][1]\n",
        "\n",
        "with torch.no_grad():\n",
        "  X = X.to(device)\n",
        "  pred = model(X)\n",
        "  predicted,actual = classes[pred[0].argmax(0)],classes[y]\n",
        "  print(f'Predicted {predicted}')\n",
        "  print(f'Actual {actual}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMWkLqtqhpTm",
        "outputId": "76e4ab45-d344-414c-eb0c-56ecc5ee227d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Ankle Boot\n",
            "Actual Ankle Boot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sBUxQNgiB1l",
        "outputId": "169509cd-bb2b-4f56-f520-619ad9b93c91"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ESCsqWlbiCkL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}